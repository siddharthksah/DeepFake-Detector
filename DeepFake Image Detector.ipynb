{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data from here https://www.kaggle.com/xhlulu/140k-real-and-fake-faces\n",
    "def build_model(pretrained):\n",
    "    model = Sequential([\n",
    "        pretrained,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#this part is prolly the most trickiest one, make sure the base path is correct cause the code looks for the files\n",
    "#respective to this path\n",
    "base_path = './real-vs-fake/'\n",
    "\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    base_path + 'train/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "valid_flow = image_gen.flow_from_directory(\n",
    "    base_path + 'valid/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_flow = image_gen.flow_from_directory(\n",
    "    base_path + 'test/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 7,038,529\n",
      "Trainable params: 6,954,881\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#download the weight from here https://www.kaggle.com/xhlulu/densenet-keras\n",
    "densenet = DenseNet121(\n",
    "    weights='./DenseNet-BC-121-32-no-top.h5',\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1562/1562 [==============================] - 59545s 38s/step - loss: 0.1209 - accuracy: 0.9505 - val_loss: 1.3828 - val_accuracy: 0.6277\n",
      "Epoch 2/3\n",
      "1562/1562 [==============================] - 29780s 19s/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.0908 - val_accuracy: 0.9698\n",
      "Epoch 3/3\n",
      "1562/1562 [==============================] - 28102s 18s/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.6224 - val_accuracy: 0.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc50817c730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps = 100000//64\n",
    "valid_steps = 20000//64\n",
    "\n",
    "model.fit(\n",
    "    train_flow,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=valid_flow,\n",
    "    validation_steps=valid_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.49576708\n",
      "AP Score: 0.4930386632643057\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59     10000\n",
      "           1       0.49      0.27      0.35     10000\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.49      0.50      0.47     20000\n",
      "weighted avg       0.49      0.50      0.47     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2835s 9s/step - loss: 0.6369 - accuracy: 0.7770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6368963122367859, 0.7769500017166138]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model(\"model.h5\")\n",
    "\n",
    "\n",
    "frame = cv2.imread('trump.jpg')\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1502162e-11\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (224, 224, 3))\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image\n",
    "\n",
    "image = load('fake_1.jpg')\n",
    "print(model.predict(image)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
